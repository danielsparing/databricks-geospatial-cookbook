{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1049fd0e-5357-44bd-8ce6-eaff002ac54c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# End-to-end example: Taking the train to the slopes\n",
    "\n",
    "![bourg](img/bourg.png)\n",
    "\n",
    "(Photo: the author)\n",
    "\n",
    "Geospatial analysis often includes combining multiple data sources. In this example, we will only use OpenStreetMap (OSM), but as you'll see one of the datasets is a LineString type and another is a Polygon type.\n",
    "\n",
    "::: {.callout-note}\n",
    "\n",
    "Why don't we use Overture Maps, you might ask, as that's already available in a cloud-native format? Very good question. Unfortunately, Overture Maps doesn't (yet) contain all datasets that you can find in OSM, so while roads and buildings are included, for example transit isn't (as of writing).\n",
    "\n",
    ":::\n",
    "\n",
    "Let's say we'd like to go skiing but would like to avoid the hassle of driving or flying, Are there slopes accessible by train? It turns out, yes -- let's find them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fc82231f-3807-4e9f-a821-d56f078ab1e7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Fetching OSM\n",
    "\n",
    "See also [Importing other formats](../other_formats/import.ipynb) on how to use DuckDB Spatial to read OSM and other file types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "07f91527-619b-46fb-9546-9bfed98002f9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install duckdb lonboard shapely --quiet\n",
    "\n",
    "import duckdb\n",
    "\n",
    "duckdb.sql(\"install spatial; load spatial;\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "af38627b-fdd9-4ba2-aa20-6ed0f0821589",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "CATALOG = \"workspace\"\n",
    "SCHEMA = \"default\"\n",
    "VOLUME = \"default\"\n",
    "\n",
    "CONTINENT = \"europe\"\n",
    "COUNTRY = \"france\"\n",
    "GEOFABRIK_URL = f\"https://download.geofabrik.de/{CONTINENT}/{COUNTRY}-latest.osm.pbf\"\n",
    "\n",
    "spark.sql(f\"use {CATALOG}.{SCHEMA}\")\n",
    "spark.sql(f\"create volume if not exists {CATALOG}.{SCHEMA}.{VOLUME}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5570f68c-8c50-4faa-a80b-5304953b41a1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "file_name = GEOFABRIK_URL.split(\"/\")[-1]\n",
    "file_basename = file_name.rsplit(\".\")[0]\n",
    "volume_file_path = f\"/Volumes/{CATALOG}/{SCHEMA}/{VOLUME}/{file_name}\"\n",
    "volume_parquet_path = f\"/Volumes/{CATALOG}/{SCHEMA}/{VOLUME}/{file_basename}.parquet\"\n",
    "tablename = f\"planet_osm_{COUNTRY}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "80e40ab8-d850-4232-a2cc-449a63715b59",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "!curl -o {volume_file_path} {GEOFABRIK_URL}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9d845371-4db7-41c1-af47-4a44c75a5274",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "duckdb.sql(\n",
    "    f\"\"\"\n",
    "copy (\n",
    "    select\n",
    "        *\n",
    "    from\n",
    "        '{volume_file_path}'\n",
    ") to '{volume_parquet_path}'\n",
    "(format parquet)\n",
    ";\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2f3ca494-9ebc-4d19-898e-02cd2526a525",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.read.parquet(volume_parquet_path).write.option(\"clusteredBy\", \"id\").saveAsTable(\n",
    "    f\"{CATALOG}.{SCHEMA}.{tablename}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c2f95955-0ecc-4212-8110-3445a5126e4d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Transform into a table with GEOMETRY with Databricks Spatial SQL\n",
    "\n",
    "See also [Databricks Spatial SQL ST functions](../stfunctions/native.ipynb), and [Delta Lake tables with GEOMETRY](../delta/GEOMETRY.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4fbe8c7f-8533-4b7a-ab9b-4bbfd35e8959",
     "showTitle": false,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1755794124504}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      }
     },
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "create or replace table skiresorts as\n",
    "with wintersports as (\n",
    "  select\n",
    "    id as wintersports_id,\n",
    "    tags.name,\n",
    "    posexplode(refs) as (pos, id)\n",
    "  from\n",
    "    planet_osm_france\n",
    "  where\n",
    "    kind = \"way\"\n",
    "    and tags.landuse = \"winter_sports\"\n",
    ")\n",
    "select\n",
    "  wintersports_id,\n",
    "  name,\n",
    "  st_makepolygon(\n",
    "    st_makeline(\n",
    "      transform(sort_array(array_agg(struct(pos, lon, lat))), x -> st_point(x.lon, x.lat, 4326))\n",
    "    )\n",
    "  ) geometry\n",
    "from\n",
    "  wintersports join planet_osm_france p using (id)\n",
    "group by\n",
    "  all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c98d6403-5ea0-4f7e-9744-340ce65d1f22",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "::: {.callout-note}\n",
    "\n",
    "As of 2025-08-20, GEOMETRY/GEOGRAPHY columns cannot be returned in a notebook yet, therefore instead of `select *`, we temporarily use the pattern, for a column `g` of type GEOMETRY/GEOGRAPHY:\n",
    "\n",
    "```sql\n",
    "select\n",
    "  * except (g),\n",
    "  st_asewkt(g) as ewkt_g\n",
    "```\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "56fce252-9064-4e1e-9b87-9ea6dfe88e9f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "select\n",
    "  * except (geometry),\n",
    "  st_asewkt(geometry) geometry\n",
    "from\n",
    "  skiresorts\n",
    "-- Returns:\n",
    "-- wintersports_id\tname\tgeometry\n",
    "-- 23079840\tIsola 2000\tSRID=4326;POLYGON((7.1524774 44.204359200000006,...))\n",
    "-- 27163365\tEstación de Esquí Aramón Formigal\tSRID=4326;POLYGON((-0.41821430000000004 42.8009106,...))\n",
    "-- ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0100d6cf-fafd-44c4-abb8-fcea3930774d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Visualize with Lonboard\n",
    "\n",
    "See also [Visualize with Lonboard](../viz/lonboard.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fd4981e5-9135-4f11-a236-2f646c0937e2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from lonboard import viz\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "dfa = (\n",
    "    spark.table(\"skiresorts\")\n",
    "    .withColumn(\"geometry\", F.expr(\"st_asbinary(geometry)\"))\n",
    "    .toArrow()\n",
    ")\n",
    "viz(duckdb.sql(\"select name, st_geomfromwkb(geometry) geometry from dfa\")).as_html()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ede33733-d59e-4e83-8e2f-ed7fedf4286c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "![wintersport](img/wintersport.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "027e44f3-ac3a-4647-b965-80944cc6e10e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Load the train network\n",
    "\n",
    "We will use similar techniques as above to load the railway network as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d1bb202d-19ed-4e06-8158-421382f3eacd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "with t1 as (\n",
    "  select\n",
    "    tags.name,\n",
    "    id as trainroute_id,\n",
    "    posexplode(refs) as (pos, id)\n",
    "  from\n",
    "    planet_osm_france\n",
    "  where\n",
    "    tags.type = 'route'\n",
    "    and tags.route = 'train'\n",
    "    and id = 2274158\n",
    "),\n",
    "t2 as (\n",
    "  select\n",
    "    t1.name,\n",
    "    p.id route_id,\n",
    "    p.* --,\n",
    "  -- posexplode(arrays_zip(p.refs, p.ref_roles, p.ref_types)) as (pos, ref),\n",
    "  -- ref[\"refs\"] id,\n",
    "  -- ref[\"ref_roles\"] role,\n",
    "  -- ref[\"ref_types\"] type\n",
    "  from\n",
    "    t1 join planet_osm_france p using (id)\n",
    "  where\n",
    "    p.tags.railway = 'rail'\n",
    ")\n",
    "select\n",
    "  *\n",
    "from\n",
    "  t2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d9a877ff-fa28-401e-aa6a-9aa4e7abbe40",
     "showTitle": false,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1755796120775}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      }
     },
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "create or replace table train_routes as\n",
    "with t1 as (\n",
    "  select\n",
    "    tags.name,\n",
    "    id as trainroute_id,\n",
    "    posexplode(refs) as (pos, id)\n",
    "  from\n",
    "    planet_osm_france\n",
    "  where\n",
    "    tags.type = 'route'\n",
    "    and tags.route = 'train'\n",
    "),\n",
    "t2 as (\n",
    "  select\n",
    "    t1.name,\n",
    "    p.id route_id,\n",
    "    posexplode(refs) as (pos, id)\n",
    "  from\n",
    "    t1 join planet_osm_france p using (id)\n",
    "  where\n",
    "    p.tags.railway = 'rail'\n",
    ")\n",
    "select\n",
    "  t2.name,\n",
    "  --subname,\n",
    "  route_id,\n",
    "  --subroute_id,\n",
    "  st_makeline(\n",
    "    transform(sort_array(array_agg(struct(pos, lon, lat))), x -> st_point(x.lon, x.lat, 4326))\n",
    "  ) geometry\n",
    "from\n",
    "  t2 join planet_osm_france p using (id)\n",
    "group by\n",
    "  all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6e4eeacd-0948-40f7-89ba-72b0c405a184",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.table(\"train_routes\").withColumn(\n",
    "    \"geometry\", F.expr(\"st_asewkt(geometry)\")\n",
    ").display()\n",
    "# Returns:\n",
    "\n",
    "# [lots of LINESTRING's]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4a575e49-e4d6-46e2-98f5-d240f60b95d4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Let's try to visualize the same way as we did for the ski _domaines_ (spoiler alert: it might not work):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9ed23d2c-e789-4852-859d-6a0a88f68965",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dfa = (\n",
    "    spark.table(\"train_routes\")\n",
    "    .withColumn(\"geometry\", F.expr(\"st_asbinary(geometry)\"))\n",
    "    .toArrow()\n",
    ")\n",
    "viz(duckdb.sql(\"select name, st_geomfromwkb(geometry) geometry from dfa\")).as_html()\n",
    "# Returns:\n",
    "# Command result size exceeds limit: Exceeded 20971520 bytes (current = 20971797)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1ce370ff-19e4-46df-90bd-39ba8d704fd3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Visualize with PMTiles\n",
    "\n",
    "The above visualization probably failed, due to the dataset being too large for the widget in Databricks. While for medium sized datasets there's another workaround by saving the Lonboard output to a seperate HTML file via `to_html()` (detailed [here](../viz/lonboard.ipynb)), let's instead use PMTiles instead that can work also for very large datasets.\n",
    "\n",
    "See also the `tippecanoe` example [here](../other_formats/export.ipynb), which we will follow now via an intermediate Parquet and FlatGeobuf file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3a46ce49-7ed4-4d18-98f5-9c88226e5a20",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Write to parquet\n",
    "spark.table(\"train_routes\").write.mode(\"overwrite\").parquet(\n",
    "    f\"/Volumes/{CATALOG}/{SCHEMA}/{VOLUME}/geometries.parquet\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a9df1fc5-15e6-4ad7-87f0-ba4f4f62593e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Write FlatGeobuf\n",
    "query = f\"\"\"\n",
    "copy (\n",
    "select \n",
    "    * replace (st_geomfromwkb(geometry) as geometry)\n",
    "from\n",
    "    read_parquet('/Volumes/{CATALOG}/{SCHEMA}/{VOLUME}/geometries.parquet/part-*.parquet')\n",
    ") to '/Volumes/{CATALOG}/{SCHEMA}/{VOLUME}/geometries.fgb'\n",
    "(FORMAT GDAL, DRIVER flatgeobuf, LAYER_CREATION_OPTIONS 'TEMPORARY_DIR=/tmp/')\"\"\"\n",
    "duckdb.sql(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "31e8e449-0b9e-432f-a873-ba18c3337f72",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sh\n",
    "# Install tippecanoe\n",
    "\n",
    "# ~3.5 min on high memory serverless https://docs.databricks.com/aws/en/compute/serverless/dependencies#high-memory\n",
    "git clone https://github.com/felt/tippecanoe.git\n",
    "cd tippecanoe\n",
    "make -j\n",
    "make install PREFIX=$HOME/.local\n",
    "rm -r tippecanoe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "950aa4ba-03c5-41a9-9f18-9033a60c6bbc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "HOME = os.environ[\"HOME\"]\n",
    "\n",
    "# see https://github.com/felt/tippecanoe/blob/main/README.md#try-this-first and e.g.\n",
    "# https://github.com/OvertureMaps/overture-tiles/blob/main/scripts/2024-07-22/places.sh\n",
    "# for possible options\n",
    "!{HOME}/.local/bin/tippecanoe -zg -rg -o /tmp/geometries.pmtiles  --simplification=10 --drop-smallest-as-needed --drop-densest-as-needed --extend-zooms-if-still-dropping --maximum-tile-bytes=2500000 --progress-interval=10 -l geometries --force /Volumes/{CATALOG}/{SCHEMA}/{VOLUME}/geometries.fgb\n",
    "# NOTE: this mv will emit an error related to updating metadata (\"mv: preserving\n",
    "# permissions for ‘[...]’: Operation not permitted\"), this can be ignored.\n",
    "!mv /tmp/geometries.pmtiles /Volumes/{CATALOG}/{SCHEMA}/{VOLUME}/geometries.pmtiles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bf9a3652-e481-48ff-9715-9e0ddc780e5f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "And, that's it! You can visualize the pmtiles file by downloading and uploading to https://pmtiles.io , or much better, by using a PMTiles viewer via Databricks Apps, an example implementation is [here](../apps/pmtiles-viewer/) and your result would look like this:\n",
    "\n",
    "![railnetwork](img/railnetwork.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e48c73f4-ceec-470a-8a47-a56cbcc7a6e4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Spatial join\n",
    "\n",
    "\n",
    "To actually answer our question of which ski resorts are closest to a train line -- for now, I leave that as an exercise to the reader as spatial joins are well covered in other tutorials -- one hint is that most probably you'd need to [`st_transform`](https://docs.databricks.com/aws/en/sql/language-manual/functions/st_transform) to a local coordinate system, because while there's an [`st_distancespheroid`](https://docs.databricks.com/aws/en/sql/language-manual/functions/st_distancespheroid) function, as of writing it only works with points."
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": "HIGH"
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 6575777883032855,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "train_to_slopes",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
