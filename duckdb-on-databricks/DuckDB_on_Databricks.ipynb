{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "462b1d0c-c0d2-4789-bd7a-cfcabfe9e893",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# DuckDB on Databricks\n",
    "\n",
    "<img src=\"https://images.unsplash.com/photo-1563286094-ad5e870b309c\" width=\"100%\">\n",
    "\n",
    "[DuckDB](https://duckdb.org/) is a formidable new single-machine analytics tool, tracing its origins to the same [Dutch research institute](https://www.cwi.nl/nl/) as Python. Crucially for this guide, it comes with a remarkably good [Spatial extension](https://duckdb.org/docs/stable/core_extensions/spatial/overview.html).\n",
    "\n",
    "While Databricks comes with its own set of geospatial features, such as [ST functions](https://docs.databricks.com/aws/en/sql/language-manual/sql-ref-st-geospatial-functions) and [H3 functions](https://docs.databricks.com/aws/en/sql/language-manual/sql-ref-h3-geospatial-functions), nothing stops you to use DuckDB on the side as well.\n",
    "\n",
    "(What you do have to keep in mind though is that while much of Databricks's tooling, namely Apache Spark, is focused on big data analysis multi-node clusters, your DuckDB instead will just run on single-node, just like e.g. Pandas would. So use single-node clusters, or [Spark UDFs](../stfunctions/duckdb_udf.ipynb).)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "07c2a00c-1b58-4da7-830c-519aff06040f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "::: {.callout-note}\n",
    "\n",
    "This was tested on Serverless notebook, Environment version 4.\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "03723ea7-33cd-42e3-b9f9-eda4f048e43e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Setting up DuckDB on Databricks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "76287d43-3e3f-486b-b658-40bd03725abc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install duckdb --quiet\n",
    "\n",
    "import duckdb\n",
    "\n",
    "# Install the Spatial Extension:\n",
    "duckdb.sql(\"install spatial; load spatial\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c04f1501-2dc5-420d-8cd1-31dbb27b58fc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "::: {.callout-note}\n",
    "\n",
    "If `install spatial` fails (especially if you are _not_ using the Free Edition or Serverless Compute, but classic compute), check whether HTTP is blocked on your (corporate) network. If so, then you need to work around it as described [here](../appendix/https_install_duckdbextension.ipynb).\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "61c64b7e-b0fd-4db4-bf5f-0f2f346229e5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "This allows you to directly use the DuckDB Spatial, for example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d2e8f1da-a69d-478e-b5bf-be92fcb16bb8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "duckdb.sql(\"select st_distance(st_point(3, 0), st_point(0, 4)) d\")\n",
    "\n",
    "# Returns:\n",
    "\n",
    "# ┌────────┐\n",
    "# │   d    │\n",
    "# │ double │\n",
    "# ├────────┤\n",
    "# │    5.0 │\n",
    "# └────────┘"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0423462f-351f-4497-a9dc-d9b12bc3ac46",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Visualize DuckDB Spatial output\n",
    "\n",
    "If your data is simply lon/lat points, you can make use of the built-in point map visualization in Databricks Notebooks if you convert the DuckDB to a Spark DataFrame via Pandas.\n",
    "\n",
    "Following the New York City pizza restaurants [example](https://docs.overturemaps.org/getting-data/duckdb/?query=Places#downloading-overture-data), but let's switch to Amsterdam:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6bbba57f-b0fc-4bb6-9493-fb3a0a610b78",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "OVERTURE_RELEASE = \"2026-02-18.0/\"  # Replace with the release you want, see https://docs.overturemaps.org/getting-data/\n",
    "\n",
    "query = duckdb.sql(\n",
    "    f\"\"\"\n",
    "with t as (\n",
    "  SELECT\n",
    "    id,\n",
    "    names.primary as name,\n",
    "    confidence AS confidence,\n",
    "    CAST(socials AS JSON) as socials,\n",
    "    geometry\n",
    "  FROM\n",
    "    read_parquet('s3://overturemaps-us-west-2/release/{OVERTURE_RELEASE}theme=places/type=place/*')\n",
    "  WHERE\n",
    "    categories.primary = 'pizza_restaurant'\n",
    "    AND bbox.xmin BETWEEN 4.7 AND 5.0\n",
    "    AND bbox.ymin BETWEEN 52.3 AND 52.4\n",
    ")\n",
    "select st_x(geometry) lon, st_y(geometry) lat, name from t\n",
    "\"\"\"\n",
    ")\n",
    "query\n",
    "\n",
    "# Returns:\n",
    "\n",
    "# ┌───────────┬────────────┬──────────────────────────────────────────┐\n",
    "# │    lon    │    lat     │                   name                   │\n",
    "# │  double   │   double   │                 varchar                  │\n",
    "# ├───────────┼────────────┼──────────────────────────────────────────┤\n",
    "# │  4.762994 │ 52.3099144 │ Per Tutti                                │\n",
    "# │ 4.7789755 │ 52.3381557 │ New York Pizza                           │\n",
    "# │ 4.7811585 │ 52.3367951 │ CiCi Pizza                               │\n",
    "# │     ·     │      ·     │       ·                                  │\n",
    "# │     ·     │      ·     │       ·                                  │\n",
    "# │     ·     │      ·     │       ·                                  │"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "41929586-a3aa-4d46-b9f4-75ca435bd8ab",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Once the result below is shown, click on the `+` icon right of the `Table` tab to add the visualization \"Map (Markers)\" such as the one shown on the below image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "959091e2-7c35-47a6-8999-e57eab0c4d5b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.createDataFrame(query.df()).display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1be5b2c3-b2de-4dd4-93c8-f56ed6e2ce56",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "![point_map](./img/point_map.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2f09c012-3c04-47d0-b187-7fa0dc751022",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Or visualize with lonboard, which will work also for other geometry types like linestrings and polygons, again following an Overture Maps example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3195aaeb-d076-4b7d-9267-0d6e6281e996",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install lonboard shapely --quiet\n",
    "\n",
    "from lonboard import viz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7d938d3d-68c4-4901-ba3c-48fc14cf5aca",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "query = duckdb.sql(\n",
    "    f\"\"\"\n",
    "  SELECT\n",
    "    subtype,\n",
    "    names.primary as name,\n",
    "    geometry\n",
    "  FROM\n",
    "    read_parquet('s3://overturemaps-us-west-2/release/{OVERTURE_RELEASE}theme=divisions/type=division_area/*')\n",
    "  WHERE\n",
    "    4.7 < bbox.xmax AND bbox.xmin < 5.0\n",
    "    AND 52.3 < bbox.ymax AND bbox.ymin < 52.4\n",
    "    AND subtype = 'county'\n",
    "    AND country = 'NL'\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "viz(query).as_html()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ccd50e72-c44d-48d9-a7fb-5e910da14979",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "![lonboard_gemeente_map](./img/lonboard_gemeente_map.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0deabc17-f414-4fa8-973c-7b040d34e5f7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Note that clicking on a polygon opens a table with its parameters, in this case the municipalities of Amsterdam and some of its neighbors.\n",
    "\n",
    "As powerful as Lonboard is, it won't be able to visualize extremely large numbers of geometries, so if you try and fail at a larger example, try filtering your objects further."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "05e9ce49-faa2-4dc5-be4d-9b8901166b00",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Write Delta Lake Tables from DuckDB\n",
    "\n",
    "If you want to write a result to a delta lake table (or temporary view), you can use Pandas as an intermediary format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "55fc4e92-c9ee-4c7a-ade4-84a3d2a9397f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.createDataFrame(query.df()).createOrReplaceTempView(\"t\")\n",
    "\n",
    "# Or write a persistent table, instead of a temporary view:\n",
    "# spark.createDataFrame(query.df()).write.saveAsTable(\"t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "80f446b2-f88e-4b9c-a9a3-2b0017370ef3",
     "showTitle": false,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1754156918738}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      }
     },
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "select\n",
    "  name\n",
    "from\n",
    "  t\n",
    "-- Returns:\n",
    "-- ┌────────────────┐\n",
    "-- │      name      │\n",
    "-- ├────────────────┤\n",
    "-- │ Haarlemmermeer │\n",
    "-- │ Aalsmeer       │\n",
    "-- │ De Ronde Venen │\n",
    "-- │ Amstelveen     │\n",
    "-- │ Ouder-Amstel   │\n",
    "-- │ Amsterdam      │\n",
    "-- │ Diemen         │\n",
    "-- │ Waterland      │\n",
    "-- └────────────────┘"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c45d3221-a136-4f4c-92bb-b1769ba28537",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Read Delta Lake Tables with DuckDB\n",
    "\n",
    "We can read moderate amount of data from a delta table to duckdb via Arrow (or Pandas). (This assumes that the data volume is not prohibitively large to load into the memory of a single machine.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e8afa572-0a0d-40c5-bd00-b09ff926212d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dfa = spark.read.table(\"t\").toArrow()\n",
    "\n",
    "query = duckdb.sql(\n",
    "    \"\"\"\n",
    "select\n",
    "    name\n",
    "from\n",
    "    dfa;\n",
    "\"\"\"\n",
    ")\n",
    "query\n",
    "\n",
    "# Returns:\n",
    "\n",
    "# ┌────────────────┐\n",
    "# │      name      │\n",
    "# │    varchar     │\n",
    "# ├────────────────┤\n",
    "# │ Haarlemmermeer │\n",
    "# │ Aalsmeer       │\n",
    "# │ De Ronde Venen │\n",
    "# │ Amstelveen     │\n",
    "# │ Ouder-Amstel   │\n",
    "# │ Amsterdam      │\n",
    "# │ Diemen         │\n",
    "# │ Waterland      │\n",
    "# └────────────────┘"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7c48d501-7c6f-40f7-9189-017cc2018ae8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Another, more scalable way to read Delta Lake tables with DuckDB is to use the Databricks [Temporary Table Credentials API](https://docs.databricks.com/api/workspace/temporarytablecredentials) (not available on Databricks Free Edition as of writing) and the DuckDB [Delta extension](https://duckdb.org/docs/stable/core_extensions/delta.html).\n",
    "\n",
    "Finally, a high-level tool to make this work would be the DuckDB extension [uc-catalog](https://github.com/duckdb/uc_catalog), but this did not reliably work for me (on either Free Edition or \"paid\" Databricks) as of writing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7a631308-f140-45f5-86a3-f77284d2a996",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Use cell magic `%%jupysql` for duckdb queries\n",
    "\n",
    "In Databricks, you can write Databricks SQL code (so not DuckDB SQL code) in SQL code cells, using the `%sql` cell magic. DuckDB is also [compatible](https://duckdb.org/docs/stable/guides/python/jupyter.html) with similar cell magic tooling, but in order to not get crossed with Databricks SQL, we'll need to use another magic, `%%jupysql` (which is also the name of the [package](https://github.com/ploomber/jupysql) that makes this possible). We can set it all up as the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "12f59984-e581-4bf6-89a2-fe4a33abc2bf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install jupysql --quiet\n",
    "%restart_python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8c44de6f-2a7a-49b9-a22b-0268c31e4f21",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%load_ext sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a5ab7b1a-7a13-4ed2-9a5c-8fe0a8f0c093",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import duckdb\n",
    "\n",
    "con = duckdb.connect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dd87272e-8bec-4eb4-8a82-5de0759acb40",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "We need to specify the connection object only at the first use of `%%jupysql`, as below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8482714b-e5f8-4e97-ad48-3237eb3777a5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%%jupysql con --alias duckdb\n",
    "install spatial; load spatial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "76fc86c4-cdc3-44cd-bdbc-2f53d8455380",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%%jupysql\n",
    "with t as (\n",
    "  SELECT\n",
    "    id,\n",
    "    names.primary as name,\n",
    "    confidence AS confidence,\n",
    "    CAST(socials AS JSON) as socials,\n",
    "    geometry\n",
    "  FROM\n",
    "    -- replace below with a recent release if needed\n",
    "    read_parquet('s3://overturemaps-us-west-2/release/2026-02-18.0/theme=places/type=place/*')\n",
    "  WHERE\n",
    "    categories.primary = 'pizza_restaurant'\n",
    "    AND bbox.xmin BETWEEN 4.7 AND 5.0\n",
    "    AND bbox.ymin BETWEEN 52.3 AND 52.4\n",
    ")\n",
    "select st_x(geometry) lon, st_y(geometry) lat, name from t\n",
    "\n",
    "-- Returns:\n",
    "\n",
    "-- Running query in 'duckdb'\n",
    "-- lon\tlat\tname\n",
    "-- 4.762994\t52.3099144\tPer Tutti\n",
    "-- 4.7789755\t52.3381557\tNew York Pizza\n",
    "-- 4.7811585\t52.3367951\tCiCi Pizza\n",
    "-- 4.7812061\t52.3368685\tJoey's kitchen\n",
    "-- 4.7500226\t52.3816196\tGastronoom\n",
    "-- 4.7905345\t52.34096\tAmon\n",
    "-- 4.7948139\t52.3512209\tMoeruth Pizza\n",
    "-- 4.797318\t52.3516662\tIl Delfino Blu\n",
    "-- 4.7988733\t52.351978\tDomino's Pizza\n",
    "-- 4.8107487\t52.3539346\tNew York Pizza\n",
    "-- Truncated to displaylimit of 10."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "50244275-938a-43c8-a3c6-d63355ea1aa6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Register DuckDB functions as Spark UDFs\n",
    "\n",
    "See [here](../stfunctions/duckdb_udf.ipynb)."
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 7430976673985011,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "DuckDB_on_Databricks",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "venv (3.13.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
